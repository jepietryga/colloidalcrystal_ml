{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "This notebook is set up to train a MaskRCNN model using Ray Tune for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-12 12:11:10,304\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-09-12 12:11:10,483\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "from torchvision.transforms import v2 as T\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import tempfile\n",
    "from functools import partial\n",
    "\n",
    "# Model Transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "# Model imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "# Data imports\n",
    "from facet_ml.classification import mask_rcnn\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Ray tune imports\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Creation Functions ###\n",
    "def get_model_instance_segmentation(num_classes,\n",
    "                                    config:dict):\n",
    "    \n",
    "    ## load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    ## Make an updated FastRCNN with backgone changes as needed\n",
    "    backbone = config.get(\"backbone\",\"resnet50\")\n",
    "    if backbone == \"mobilenet_v2\":\n",
    "        backbone = torchvision.models.mobilenet_v2(weights=\"DEFAULT\").features\n",
    "        backbone.out_channels = 1280\n",
    "        fast_rcnn = FasterRCNN(backbone, in_features=in_features, num_classes=num_classes,)\n",
    "        model.roi_heads.box_predictor = fast_rcnn\n",
    "    else:\n",
    "        # Use defualt resnet50 bacbone\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_instance_segmentation(num_classes,config):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_optimizer(model,config):\n",
    "    '''\n",
    "    Get an optimzier based on the config settings\n",
    "    '''\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if config[\"optimizer\"] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(params,\n",
    "                         lr=config[\"lr\"],\n",
    "                        weight_decay=config[\"weight_decay\"],\n",
    "                        betas=config[\"betas\"]\n",
    "            )\n",
    "    elif config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            params,\n",
    "            lr=config[\"lr\"],\n",
    "            momentum=config[\"momentum\"],\n",
    "            weight_decay=config[\"weight_decay\"] # .0005 starting\n",
    "        )\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(optimizer,config):\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=3,\n",
    "        gamma=config[\"gamma\"]\n",
    "    )\n",
    "    return lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Transforms and Data ###\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "        transforms.append(T.RandomRotation(90))\n",
    "        transforms.append(T.RandomResizedCrop(size=256, scale=(0.6, 1.4)))\n",
    "        T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.0)\n",
    "        # transforms.append(T.RandomCrop(size=(224, 224)))\n",
    "\n",
    "\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def load_colloidal_data(data_dir=r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\ProcessedData\\Coco_v5\"\n",
    "):\n",
    "    train_dir = Path(data_dir) / \"train\"\n",
    "    test_dir  = Path(data_dir) / \"test\"\n",
    "    cd_train = mask_rcnn.ManualCocoColloidalDataset(\n",
    "        str(train_dir),\n",
    "        str(train_dir / \"_annotations.coco.json\"),\n",
    "        transforms=get_transform(True)\n",
    "    )\n",
    "    cd_test = mask_rcnn.ManualCocoColloidalDataset(\n",
    "        str(test_dir),\n",
    "        str(Path(test_dir) / \"_annotations.coco.json\"),\n",
    "        transforms=get_transform(False)\n",
    "    )\n",
    "\n",
    "\n",
    "    return cd_train, cd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ray Tune config parameters\n",
    "ray_config ={\n",
    "    # Opt choice\n",
    "    \"optimizer\": tune.choice([\"Adam\",\"SGD\"]),\n",
    "\n",
    "    # Region Choices\n",
    "\n",
    "    # General choices\n",
    "    \"lr\": tune.loguniform(1e-4,1e-1),\n",
    "    \"betas\":  tune.choice([(0.9, 0.999), (0.5, 0.999)]),\n",
    "    \"momentum\": tune.uniform(0.5, 0.9),\n",
    "    \"weight_decay\": tune.loguniform(1e-4,1e-1),\n",
    "    \"gamma\": tune.uniform(0.1, 0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ray Tune Functions ##\n",
    "\n",
    "def train_colloidal(config,data_dir):\n",
    "    '''\n",
    "    Ray tune train loop\n",
    "    '''\n",
    "    device = \"cuda\"\n",
    "\n",
    "    model = get_model_instance_segmentation(2,config)\n",
    "    model.to(device)\n",
    "    optimizer = get_optimizer(model, config)\n",
    "    scheduler = get_scheduler(optimizer, config)\n",
    "\n",
    "    checkpoint = get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"rb\") as fp:\n",
    "                checkpoint_state = pickle.load(fp)\n",
    "            start_epoch = checkpoint_state[\"epoch\"]\n",
    "            model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    trainset, testset = load_colloidal_data(data_dir)\n",
    "    def collate_fn(batch):\n",
    "        '''\n",
    "        Collation function receives [(image_1, targets_1{masks,boxes,labels}), (image_10, targets_1{masks,boxes,labels})...]\n",
    "        Need to stack image_1\n",
    "        '''\n",
    "        images = [item[0] for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        # return tuple(zip(*batch))\n",
    "        return images,targets\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=2,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=2,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, targets = data\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [\n",
    "                {\n",
    "                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                    for k, v in t.items()\n",
    "                }\n",
    "                for t in targets\n",
    "            ]\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses_reduced = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses_reduced.item()\n",
    "\n",
    "            print(losses)\n",
    "            if not math.isfinite(loss_value):\n",
    "                print(f\"Loss is {loss_value}, stopping training\")\n",
    "                # print(loss_dict_reduced)\n",
    "                sys.exit(1)\n",
    "            \n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            test_loss = 0.0\n",
    "            test_steps = 0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "\n",
    "            for i, data in enumerate(test_loader,0):\n",
    "                with torch.no_grad():\n",
    "                    images, targets = data\n",
    "                    images = list(image.to(device) for image in images)\n",
    "                    targets = [\n",
    "                        {\n",
    "                            k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                            for k, v in t.items()\n",
    "                        }\n",
    "                        for t in targets\n",
    "                    ]\n",
    "                    loss_dict = model(images, targets)\n",
    "                    losses_reduced = sum(loss for loss in loss_dict.values())\n",
    "                    test_loss += losses_reduced\n",
    "                    test_steps += 1\n",
    "            \n",
    "            checkpoint_data = {\n",
    "                \"epoch\": epoch,\n",
    "                \"net_state_dict\":model.state_dict(),\n",
    "                \"optimizer_state_dict\":optimizer.state_dict()\n",
    "            }\n",
    "            with tempfile.TemporaryDirectory() as checkpoint_dir:\n",
    "                data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "                with open(data_path, \"wb\") as fp:\n",
    "                    pickle.dump(checkpoint_data, fp)\n",
    "\n",
    "                checkpoint = Checkpoint.from_directory(checkpoint_dir)\n",
    "                train.report(\n",
    "                    {\"loss\": test_loss.to(\"cpu\").detach().numpy() / test_steps, \n",
    "                    #  \"accuracy\": correct / total\n",
    "                     },\n",
    "                    checkpoint=checkpoint,\n",
    "                )\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ray.tune.search.sample.Categorical object at 0x000002B061ECCF70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\train\\_internal\\session.py:652: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9019, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\train\\_internal\\session.py:652: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.0724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9982.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss is nan, stopping training\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.abspath(r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\ProcessedData\\Coco_v5\")\n",
    "print(ray_config[\"optimizer\"])\n",
    "test_config ={\n",
    "    # Opt choice\n",
    "    \"optimizer\": \"SGD\",\n",
    "\n",
    "    # Region Choices\n",
    "\n",
    "    # General choices\n",
    "    \"lr\": 0.005,\n",
    "    \"betas\":  (0.9, 0.999),\n",
    "    \"momentum\":0.9,\n",
    "    \"weight_decay\": .5,\n",
    "    \"gamma\": 0.6\n",
    "}\n",
    "train_colloidal(test_config,data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config, num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
    "    data_dir = os.path.abspath(r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\ProcessedData\\Coco_v5\")\n",
    "    load_colloidal_data(data_dir)\n",
    "    # config = {\n",
    "    #     \"l1\": tune.choice([2**i for i in range(9)]),\n",
    "    #     \"l2\": tune.choice([2**i for i in range(9)]),\n",
    "    #     \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    #     \"batch_size\": tune.choice([2, 4, 8, 16]),\n",
    "    # }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    def short_dirname(trial):\n",
    "        return \"trial_\" + str(trial.trial_id)\n",
    "    \n",
    "    result = tune.run(\n",
    "        partial(train_colloidal, data_dir=data_dir),\n",
    "        # resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        trial_dirname_creator=short_dirname,\n",
    "        max_concurrent_trials=4\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "    # print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 12:11:12,864\tINFO worker.py:1783 -- Started a local Ray instance.\n",
      "2024-09-12 12:11:14,054\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-09-12 12:11:14,055\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-09-12 14:10:41</td></tr>\n",
       "<tr><td>Running for: </td><td>01:59:27.85        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.8/31.8 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=26<br>Bracket: Iter 8.000: -3.0289276838302612 | Iter 4.000: -3.5131516456604004 | Iter 2.000: -3.2401907444000244 | Iter 1.000: -8.847337245941162<br>Logical resource usage: 1.0/28 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 4<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_colloidal_03f42_00008</td><td style=\"text-align: right;\">           1</td><td>C:/Users/Jacob/AppData/Local/Temp/ray/session_2024-09-12_12-11-11_479769_26952/artifacts/2024-09-12_12-11-14/train_colloidal_2024-09-12_12-11-14/driver_artifacts/trial_03f42_00008/error.txt</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00015</td><td style=\"text-align: right;\">           1</td><td>C:/Users/Jacob/AppData/Local/Temp/ray/session_2024-09-12_12-11-11_479769_26952/artifacts/2024-09-12_12-11-14/train_colloidal_2024-09-12_12-11-14/driver_artifacts/trial_03f42_00015/error.txt</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00022</td><td style=\"text-align: right;\">           1</td><td>C:/Users/Jacob/AppData/Local/Temp/ray/session_2024-09-12_12-11-11_479769_26952/artifacts/2024-09-12_12-11-14/train_colloidal_2024-09-12_12-11-14/driver_artifacts/trial_03f42_00022/error.txt</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00023</td><td style=\"text-align: right;\">           1</td><td>C:/Users/Jacob/AppData/Local/Temp/ray/session_2024-09-12_12-11-11_479769_26952/artifacts/2024-09-12_12-11-14/train_colloidal_2024-09-12_12-11-14/driver_artifacts/trial_03f42_00023/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>betas       </th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th>optimizer  </th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">            loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_colloidal_03f42_00000</td><td>TERMINATED</td><td>127.0.0.1:34412</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.553449</td><td style=\"text-align: right;\">0.0130623  </td><td style=\"text-align: right;\">  0.801122</td><td>Adam       </td><td style=\"text-align: right;\">   0.00108585 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        229.197 </td><td style=\"text-align: right;\">   inf          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00001</td><td>TERMINATED</td><td>127.0.0.1:20128</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.397102</td><td style=\"text-align: right;\">0.00125083 </td><td style=\"text-align: right;\">  0.604578</td><td>SGD        </td><td style=\"text-align: right;\">   0.000301029</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">       6205.02  </td><td style=\"text-align: right;\">     3.10163    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00002</td><td>TERMINATED</td><td>127.0.0.1:10444</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.354488</td><td style=\"text-align: right;\">0.000180204</td><td style=\"text-align: right;\">  0.736511</td><td>SGD        </td><td style=\"text-align: right;\">   0.00884615 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">       6219.1   </td><td style=\"text-align: right;\">     3.02893    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00003</td><td>TERMINATED</td><td>127.0.0.1:19260</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.662824</td><td style=\"text-align: right;\">0.00253106 </td><td style=\"text-align: right;\">  0.741076</td><td>Adam       </td><td style=\"text-align: right;\">   0.0357407  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        229.046 </td><td style=\"text-align: right;\">     1.10258e+08</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00004</td><td>TERMINATED</td><td>127.0.0.1:8976 </td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.378463</td><td style=\"text-align: right;\">0.000818231</td><td style=\"text-align: right;\">  0.605687</td><td>Adam       </td><td style=\"text-align: right;\">   0.00021017 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">       1726.07  </td><td style=\"text-align: right;\">    16.8359     </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00005</td><td>TERMINATED</td><td>127.0.0.1:20088</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.139124</td><td style=\"text-align: right;\">0.00906127 </td><td style=\"text-align: right;\">  0.539653</td><td>SGD        </td><td style=\"text-align: right;\">   0.00535453 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">       5995.78  </td><td style=\"text-align: right;\">     3.30357    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00006</td><td>TERMINATED</td><td>127.0.0.1:11856</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.842264</td><td style=\"text-align: right;\">0.00304824 </td><td style=\"text-align: right;\">  0.518698</td><td>Adam       </td><td style=\"text-align: right;\">   0.00387564 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.8512</td><td style=\"text-align: right;\">     2.09828e+10</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00007</td><td>TERMINATED</td><td>127.0.0.1:23384</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.201527</td><td style=\"text-align: right;\">0.000102438</td><td style=\"text-align: right;\">  0.875539</td><td>SGD        </td><td style=\"text-align: right;\">   0.0468364  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">       4172.16  </td><td style=\"text-align: right;\">     6.5979     </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00009</td><td>TERMINATED</td><td>127.0.0.1:16644</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.644479</td><td style=\"text-align: right;\">0.00725294 </td><td style=\"text-align: right;\">  0.823485</td><td>SGD        </td><td style=\"text-align: right;\">   0.00233057 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        104.723 </td><td style=\"text-align: right;\">     7.08466e+06</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00010</td><td>TERMINATED</td><td>127.0.0.1:3368 </td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.157441</td><td style=\"text-align: right;\">0.00330996 </td><td style=\"text-align: right;\">  0.55121 </td><td>Adam       </td><td style=\"text-align: right;\">   0.000204109</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.8196</td><td style=\"text-align: right;\">     3.37972e+12</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00011</td><td>TERMINATED</td><td>127.0.0.1:3780 </td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.800666</td><td style=\"text-align: right;\">0.00616648 </td><td style=\"text-align: right;\">  0.652111</td><td>Adam       </td><td style=\"text-align: right;\">   0.00196423 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.4745</td><td style=\"text-align: right;\">     2.58188e+22</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00012</td><td>TERMINATED</td><td>127.0.0.1:22496</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.512368</td><td style=\"text-align: right;\">0.000165174</td><td style=\"text-align: right;\">  0.527764</td><td>Adam       </td><td style=\"text-align: right;\">   0.000618802</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        319.387 </td><td style=\"text-align: right;\">     2.45547    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00013</td><td>TERMINATED</td><td>127.0.0.1:18756</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.715194</td><td style=\"text-align: right;\">0.0803385  </td><td style=\"text-align: right;\">  0.550976</td><td>SGD        </td><td style=\"text-align: right;\">   0.0556681  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.5443</td><td style=\"text-align: right;\">379862          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00014</td><td>TERMINATED</td><td>127.0.0.1:24744</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.800438</td><td style=\"text-align: right;\">0.000176006</td><td style=\"text-align: right;\">  0.870324</td><td>Adam       </td><td style=\"text-align: right;\">   0.0454401  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        300.513 </td><td style=\"text-align: right;\">     2.59295    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00016</td><td>TERMINATED</td><td>127.0.0.1:7804 </td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.233023</td><td style=\"text-align: right;\">0.0127417  </td><td style=\"text-align: right;\">  0.542573</td><td>Adam       </td><td style=\"text-align: right;\">   0.078237   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.4451</td><td style=\"text-align: right;\">   inf          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00017</td><td>TERMINATED</td><td>127.0.0.1:19324</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.240308</td><td style=\"text-align: right;\">0.00284372 </td><td style=\"text-align: right;\">  0.698555</td><td>SGD        </td><td style=\"text-align: right;\">   0.0156305  </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        479.092 </td><td style=\"text-align: right;\">     3.18563    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00018</td><td>TERMINATED</td><td>127.0.0.1:35752</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.22486 </td><td style=\"text-align: right;\">0.00014629 </td><td style=\"text-align: right;\">  0.515483</td><td>Adam       </td><td style=\"text-align: right;\">   0.00705027 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        654.983 </td><td style=\"text-align: right;\">     2.61865    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00019</td><td>TERMINATED</td><td>127.0.0.1:35256</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.135612</td><td style=\"text-align: right;\">0.00112464 </td><td style=\"text-align: right;\">  0.8892  </td><td>SGD        </td><td style=\"text-align: right;\">   0.000243304</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        249.044 </td><td style=\"text-align: right;\">     3.27609    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00020</td><td>TERMINATED</td><td>127.0.0.1:35244</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.480478</td><td style=\"text-align: right;\">0.0413966  </td><td style=\"text-align: right;\">  0.566258</td><td>SGD        </td><td style=\"text-align: right;\">   0.00212596 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.4563</td><td style=\"text-align: right;\">    72.2422     </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00021</td><td>TERMINATED</td><td>127.0.0.1:17584</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.638572</td><td style=\"text-align: right;\">0.0121791  </td><td style=\"text-align: right;\">  0.553713</td><td>Adam       </td><td style=\"text-align: right;\">   0.0194951  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        232.863 </td><td style=\"text-align: right;\">   inf          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00024</td><td>TERMINATED</td><td>127.0.0.1:35644</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.640837</td><td style=\"text-align: right;\">0.00201792 </td><td style=\"text-align: right;\">  0.774252</td><td>SGD        </td><td style=\"text-align: right;\">   0.0016514  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        307.619 </td><td style=\"text-align: right;\">     3.63617    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00025</td><td>TERMINATED</td><td>127.0.0.1:19364</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.809533</td><td style=\"text-align: right;\">0.00157369 </td><td style=\"text-align: right;\">  0.663326</td><td>SGD        </td><td style=\"text-align: right;\">   0.0073544  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        291.752 </td><td style=\"text-align: right;\">     3.51315    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00026</td><td>TERMINATED</td><td>127.0.0.1:23300</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.469726</td><td style=\"text-align: right;\">0.0525793  </td><td style=\"text-align: right;\">  0.674077</td><td>SGD        </td><td style=\"text-align: right;\">   0.00757104 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        125.139 </td><td style=\"text-align: right;\">    28.3515     </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00027</td><td>TERMINATED</td><td>127.0.0.1:18736</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.515381</td><td style=\"text-align: right;\">0.00957663 </td><td style=\"text-align: right;\">  0.550968</td><td>Adam       </td><td style=\"text-align: right;\">   0.000504087</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        125.848 </td><td style=\"text-align: right;\">     2.33848e+30</td></tr>\n",
       "<tr><td>train_colloidal_03f42_00028</td><td>TERMINATED</td><td>127.0.0.1:10124</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.530064</td><td style=\"text-align: right;\">0.000216033</td><td style=\"text-align: right;\">  0.745637</td><td>Adam       </td><td style=\"text-align: right;\">   0.000435893</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        161.454 </td><td style=\"text-align: right;\">     3.29937    </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00029</td><td>TERMINATED</td><td>127.0.0.1:28928</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.179916</td><td style=\"text-align: right;\">0.00190494 </td><td style=\"text-align: right;\">  0.873614</td><td>Adam       </td><td style=\"text-align: right;\">   0.00466746 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.0158</td><td style=\"text-align: right;\"> 16142.6        </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00008</td><td>ERROR     </td><td>127.0.0.1:9652 </td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.351917</td><td style=\"text-align: right;\">0.0214161  </td><td style=\"text-align: right;\">  0.678759</td><td>Adam       </td><td style=\"text-align: right;\">   0.000164164</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.1802</td><td style=\"text-align: right;\">   nan          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00015</td><td>ERROR     </td><td>127.0.0.1:27284</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.85396 </td><td style=\"text-align: right;\">0.0784111  </td><td style=\"text-align: right;\">  0.800875</td><td>Adam       </td><td style=\"text-align: right;\">   0.00188257 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.5247</td><td style=\"text-align: right;\">   nan          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00022</td><td>ERROR     </td><td>127.0.0.1:9580 </td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.63976 </td><td style=\"text-align: right;\">0.0818124  </td><td style=\"text-align: right;\">  0.649901</td><td>Adam       </td><td style=\"text-align: right;\">   0.0295878  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.2235</td><td style=\"text-align: right;\">   nan          </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00023</td><td>ERROR     </td><td>127.0.0.1:6344 </td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.887011</td><td style=\"text-align: right;\">0.0977033  </td><td style=\"text-align: right;\">  0.862696</td><td>Adam       </td><td style=\"text-align: right;\">   0.00015852 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         31.1436</td><td style=\"text-align: right;\">   nan          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=10444)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(8.0813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(7.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19260)\u001b[0m tensor(8.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=34412)\u001b[0m tensor(5.9127, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">            loss</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_colloidal_03f42_00000</td><td style=\"text-align: right;\">   inf          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00001</td><td style=\"text-align: right;\">     3.10163    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00002</td><td style=\"text-align: right;\">     3.02893    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00003</td><td style=\"text-align: right;\">     1.10258e+08</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00004</td><td style=\"text-align: right;\">    16.8359     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00005</td><td style=\"text-align: right;\">     3.30357    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00006</td><td style=\"text-align: right;\">     2.09828e+10</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00007</td><td style=\"text-align: right;\">     6.5979     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00008</td><td style=\"text-align: right;\">   nan          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00009</td><td style=\"text-align: right;\">     7.08466e+06</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00010</td><td style=\"text-align: right;\">     3.37972e+12</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00011</td><td style=\"text-align: right;\">     2.58188e+22</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00012</td><td style=\"text-align: right;\">     2.45547    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00013</td><td style=\"text-align: right;\">379862          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00014</td><td style=\"text-align: right;\">     2.59295    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00015</td><td style=\"text-align: right;\">   nan          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00016</td><td style=\"text-align: right;\">   inf          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00017</td><td style=\"text-align: right;\">     3.18563    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00018</td><td style=\"text-align: right;\">     2.61865    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00019</td><td style=\"text-align: right;\">     3.27609    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00020</td><td style=\"text-align: right;\">    72.2422     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00021</td><td style=\"text-align: right;\">   inf          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00022</td><td style=\"text-align: right;\">   nan          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00023</td><td style=\"text-align: right;\">   nan          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00024</td><td style=\"text-align: right;\">     3.63617    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00025</td><td style=\"text-align: right;\">     3.51315    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00026</td><td style=\"text-align: right;\">    28.3515     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00027</td><td style=\"text-align: right;\">     2.33848e+30</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00028</td><td style=\"text-align: right;\">     3.29937    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_03f42_00029</td><td style=\"text-align: right;\"> 16142.6        </td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000000)\n",
      "\u001b[36m(func pid=19260)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(func pid=19260)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2024-09-12 12:15:06,345\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "NaN or Inf found in input tensor.\n",
      "2024-09-12 12:15:06,444\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=34412)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00000/checkpoint_000000)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(func pid=20088)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=20088)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=8976)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=8976)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(7.2119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(3.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=8976)\u001b[0m tensor(11.1042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20088)\u001b[0m tensor(8.8892, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000001)\n",
      "\u001b[36m(func pid=20128)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00001/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(4.4884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=8976)\u001b[0m tensor(5.5953, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000002)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20088)\u001b[0m tensor(2.6395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=10444)\u001b[0m tensor(4.2694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.8671, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20088)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00005/checkpoint_000001)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-09-12 12:43:57,162\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=11856)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=11856)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=8976)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00004/checkpoint_000001)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(2.8731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(3.0673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20088)\u001b[0m tensor(4.0548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=11856)\u001b[0m tensor(9.8381, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000004)\n",
      "\u001b[36m(func pid=20128)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00001/checkpoint_000004)\n",
      "2024-09-12 12:44:27,815\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=11856)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00006/checkpoint_000000)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(func pid=23384)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=23384)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(3.4427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.7722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20088)\u001b[0m tensor(30.3317, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=23384)\u001b[0m tensor(7.3120, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=23384)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00007/checkpoint_000000)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(2.8396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.9092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20088)\u001b[0m tensor(2.7556, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000006)\n",
      "\u001b[36m(func pid=20128)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00001/checkpoint_000006)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=23384)\u001b[0m tensor(6.5855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.6954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=10444)\u001b[0m tensor(2.5689, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20088)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00005/checkpoint_000004)\n",
      "\u001b[36m(func pid=20128)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00001/checkpoint_000007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.4392, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:54:03,224\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=23384)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00007/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20088)\u001b[0m tensor(13.6717, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000007)\n",
      "\u001b[36m(func pid=9652)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=9652)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=20128)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00001/checkpoint_000008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(2.6182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=9652)\u001b[0m tensor(9.3498, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000008)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20088)\u001b[0m tensor(3.4934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=20128)\u001b[0m tensor(2.4619, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=9652)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00008/checkpoint_000000)\n",
      "\u001b[36m(func pid=20088)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00005/checkpoint_000006)\n",
      "2024-09-12 13:54:42,228\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10444)\u001b[0m tensor(2.4638, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=16644)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=16644)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=20128)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00001/checkpoint_000009)\n",
      "2024-09-12 13:54:54,475\tERROR tune_controller.py:1331 -- Trial task failed for trial train_colloidal_03f42_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 873, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: de733cd3639a7e291e02ced501000000\n",
      "\tpid: 9652\n",
      "\tnamespace: 5ea934c1-62a9-4312-a213-23361219a7ea\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffde733cd3639a7e291e02ced501000000 Worker ID: c87f7c0096a77534feb8f5532f2d57c57a7afec0212c8c8f46d4f8d0 Node ID: 1840945993186c985884395cd85cb7685e4524dac9e433ce3e7ae42d Worker IP address: 127.0.0.1 Worker port: 53709 Worker PID: 9652 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:54:54,481\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=9652)\u001b[0m tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=9652)\u001b[0m Loss is nan, stopping training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:54:56,337\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=10444)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00002/checkpoint_000009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=20088)\u001b[0m tensor(3.1801, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=3368)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=3368)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=16644)\u001b[0m tensor(8.7886, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:55:06,913\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=20088)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00005/checkpoint_000007)\n",
      "\u001b[36m(func pid=3780)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=3780)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=22496)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=22496)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=16644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00009/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=3368)\u001b[0m tensor(8.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=3780)\u001b[0m tensor(8.4376, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:55:24,616\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=3368)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00010/checkpoint_000000)\n",
      "2024-09-12 13:55:25,946\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=16644)\u001b[0m tensor(2.7255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=22496)\u001b[0m tensor(10.0544, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=18756)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=18756)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=3780)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00011/checkpoint_000000)\n",
      "\u001b[36m(func pid=16644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00009/checkpoint_000001)\n",
      "\u001b[36m(func pid=24744)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=24744)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=18756)\u001b[0m tensor(8.7528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=24744)\u001b[0m tensor(6.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=16644)\u001b[0m tensor(3.5496, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:55:55,525\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=18756)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00013/checkpoint_000000)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.9866, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=27284)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=27284)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000000)\n",
      "\u001b[36m(func pid=16644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00009/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.8268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=27284)\u001b[0m tensor(10.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=16644)\u001b[0m tensor(66.3349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.3543, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000001)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-09-12 13:56:30,588\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=22496)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00012/checkpoint_000002)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(func pid=7804)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=7804)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.3521, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:56:49,618\tERROR tune_controller.py:1331 -- Trial task failed for trial train_colloidal_03f42_00015\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 873, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: a38ab862ca2ef2f566659a6f01000000\n",
      "\tpid: 27284\n",
      "\tnamespace: 5ea934c1-62a9-4312-a213-23361219a7ea\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffa38ab862ca2ef2f566659a6f01000000 Worker ID: cce792ace74bfc8c4251bea361785488b7f5f7d39474a6ad198dcacc Node ID: 1840945993186c985884395cd85cb7685e4524dac9e433ce3e7ae42d Worker IP address: 127.0.0.1 Worker port: 53910 Worker PID: 27284 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n",
      "\u001b[36m(func pid=27284)\u001b[0m tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=27284)\u001b[0m Loss is nan, stopping training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 13:56:49,625\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=7804)\u001b[0m tensor(5.8713, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.2480, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=19324)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "NaN or Inf found in input tensor.\n",
      "2024-09-12 13:56:59,622\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=7804)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00016/checkpoint_000000)\n",
      "\u001b[36m(func pid=35752)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=35752)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=22496)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00012/checkpoint_000003)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m tensor(9.2268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.1570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35752)\u001b[0m tensor(8.1625, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000003)\n",
      "\u001b[36m(func pid=22496)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00012/checkpoint_000004)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19324)\u001b[0m tensor(2.7686, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000004)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.1365, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00017/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.5619, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=22496)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00012/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.4801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19324)\u001b[0m tensor(3.4163, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000005)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19324)\u001b[0m tensor(3.2750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.3024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.5860, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00017/checkpoint_000003)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000002)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m tensor(3.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.5768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.1607, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00017/checkpoint_000004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.3357, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000007)\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000003)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.2047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19324)\u001b[0m tensor(3.4087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=22496)\u001b[0m tensor(2.3238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.5351, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000008)\n",
      "\u001b[36m(func pid=19324)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00017/checkpoint_000005)\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000004)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m tensor(2.7961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=24744)\u001b[0m tensor(2.1743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=22496)\u001b[0m tensor(1.9997, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19324)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00017/checkpoint_000006)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.2047, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:00:29,686\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=22496)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00012/checkpoint_000009)\n",
      "2024-09-12 14:00:29,789\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=35256)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=35256)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=24744)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00014/checkpoint_000009)\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(5.7696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35244)\u001b[0m tensor(8.8664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19324)\u001b[0m tensor(2.7986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.3633, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:01:04,153\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=35244)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=35244)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=35244)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00020/checkpoint_000000)\n",
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000000)\n",
      "\u001b[36m(func pid=17584)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=17584)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(4.2942, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(3.0672, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(2.8177, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000003)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(2.8885, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(2.7057, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(2.8716, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000006)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35256)\u001b[0m tensor(2.4647, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:04:42,780\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=35256)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00019/checkpoint_000007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=17584)\u001b[0m tensor(8.1162, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=9580)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=9580)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-09-12 14:04:52,409\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=19324)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00017/checkpoint_000007)\n",
      "\u001b[36m(func pid=6344)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=6344)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000006)\n",
      "NaN or Inf found in input tensor.\n",
      "2024-09-12 14:05:00,616\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=17584)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00021/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=9580)\u001b[0m tensor(9.2500, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35644)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=35644)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=9580)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00022/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=6344)\u001b[0m tensor(7.7901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35644)\u001b[0m tensor(5.7055, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000007)\n",
      "\u001b[36m(func pid=6344)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00023/checkpoint_000000)\n",
      "2024-09-12 14:05:35,562\tERROR tune_controller.py:1331 -- Trial task failed for trial train_colloidal_03f42_00022\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 873, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: aa551f0a4a3cd09d6e68685b01000000\n",
      "\tpid: 9580\n",
      "\tnamespace: 5ea934c1-62a9-4312-a213-23361219a7ea\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffaa551f0a4a3cd09d6e68685b01000000 Worker ID: 3345395cc20eee85c5c434ef6868f66825af6c089e422daf9a9beb09 Node ID: 1840945993186c985884395cd85cb7685e4524dac9e433ce3e7ae42d Worker IP address: 127.0.0.1 Worker port: 54341 Worker PID: 9580 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n",
      "\u001b[36m(func pid=9580)\u001b[0m tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=9580)\u001b[0m Loss is nan, stopping training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:05:35,567\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.3664, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19364)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=19364)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=35644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00024/checkpoint_000000)\n",
      "2024-09-12 14:05:48,042\tERROR tune_controller.py:1331 -- Trial task failed for trial train_colloidal_03f42_00023\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 873, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: wrap_function.<locals>.ImplicitFunc\n",
      "\tactor_id: ab033cf7d15a6e79612d6fe201000000\n",
      "\tpid: 6344\n",
      "\tnamespace: 5ea934c1-62a9-4312-a213-23361219a7ea\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=6344)\u001b[0m tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=6344)\u001b[0m Loss is nan, stopping training\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffab033cf7d15a6e79612d6fe201000000 Worker ID: 879ff3652676aca15337823cf6eb4f347523b99e2bb45768ca151963 Node ID: 1840945993186c985884395cd85cb7685e4524dac9e433ce3e7ae42d Worker IP address: 127.0.0.1 Worker port: 54359 Worker PID: 6344 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:05:48,046\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35644)\u001b[0m tensor(4.0804, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=23300)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=23300)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19364)\u001b[0m tensor(7.9016, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=35644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00024/checkpoint_000001)\n",
      "\u001b[36m(func pid=19364)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00025/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=23300)\u001b[0m tensor(5.8830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35644)\u001b[0m tensor(3.1771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35752)\u001b[0m tensor(2.1353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19364)\u001b[0m tensor(2.8881, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:07:56,452\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=23300)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00026/checkpoint_000000)\n",
      "\u001b[36m(func pid=35644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00024/checkpoint_000002)\n",
      "2024-09-12 14:07:57,641\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=18736)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=18736)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=35752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00018/checkpoint_000009)\n",
      "\u001b[36m(func pid=19364)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00025/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=18736)\u001b[0m tensor(8.2184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=10124)\u001b[0m tensor(7.8781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=19364)\u001b[0m tensor(2.6472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=35644)\u001b[0m tensor(2.8815, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19364)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00025/checkpoint_000002)\n",
      "\u001b[36m(func pid=10124)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=10124)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-09-12 14:10:05,522\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=18736)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00027/checkpoint_000000)\n",
      "2024-09-12 14:10:11,467\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=35644)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00024/checkpoint_000003)\n",
      "\u001b[36m(func pid=28928)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=28928)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=10124)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00028/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=19364)\u001b[0m tensor(3.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\u001b[36m(func pid=28928)\u001b[0m tensor(9.3012, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:10:31,026\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=19364)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00025/checkpoint_000003)\n",
      "2024-09-12 14:10:32,797\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=28928)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00029/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10124)\u001b[0m tensor(3.4085, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 14:10:41,919\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "2024-09-12 14:10:41,941\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14' in 0.0205s.\n",
      "\u001b[36m(func pid=10124)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14/trial_03f42_00028/checkpoint_000001)\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_colloidal_03f42_00008, train_colloidal_03f42_00015, train_colloidal_03f42_00022, train_colloidal_03f42_00023])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mray_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config, num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshort_dirname\u001b[39m(trial):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m---> 21\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_colloidal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_dirname_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshort_dirname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_concurrent_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[0;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_best_trial(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_trial\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\tune\\tune.py:1035\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_colloidal_03f42_00008, train_colloidal_03f42_00015, train_colloidal_03f42_00022, train_colloidal_03f42_00023])"
     ]
    }
   ],
   "source": [
    "main(ray_config,num_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config:  {'optimizer': 'Adam', 'lr': 0.00016517420107310982, 'betas': [0.5, 0.999], 'momentum': 0.5277638298935976, 'weight_decay': 0.0006188018644099798, 'gamma': 0.512368076225412}\n",
      "Best trial final result:  {'loss': 2.4554710388183594, 'timestamp': 1726167629, 'checkpoint_dir_name': 'checkpoint_000009', 'should_checkpoint': True, 'done': True, 'training_iteration': 10, 'trial_id': '03f42_00012', 'date': '2024-09-12_14-00-29', 'time_this_iter_s': 38.13473606109619, 'time_total_s': 319.3866858482361, 'pid': 22496, 'hostname': 'DESKTOP-RD74FOL', 'node_ip': '127.0.0.1', 'config': {'optimizer': 'Adam', 'lr': 0.00016517420107310982, 'betas': [0.5, 0.999], 'momentum': 0.5277638298935976, 'weight_decay': 0.0006188018644099798, 'gamma': 0.512368076225412}, 'time_since_restore': 319.3866858482361, 'iterations_since_restore': 10, 'experiment_tag': '12_betas=0_5_0_999,gamma=0.5124,lr=0.0002,momentum=0.5278,optimizer=Adam,weight_decay=0.0006'}\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "folder_path = r\"C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14\" \n",
    "analysis = ExperimentAnalysis(folder_path)\n",
    "\n",
    "completed_trials = [trial for trial in analysis.trials if trial.status == \"TERMINATED\"]\n",
    "failed_trials = [trial for trial in analysis.trials if trial.status == \"ERROR\"]\n",
    "\n",
    "best_trial = min(completed_trials, key=lambda trial: trial.last_result[\"loss\"])\n",
    "\n",
    "# Print the best performing trial and its results\n",
    "print(\"Best trial config: \", best_trial.config)\n",
    "print(\"Best trial final result: \", best_trial.last_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colloidal_crystal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
