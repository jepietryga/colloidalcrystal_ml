{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Goal </h2>\n",
    "<p> This notebook uses ray tune to find training parameters for the MaskRCNN model. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-03 23:40:42,949\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-03 23:40:43,155\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "from torchvision.transforms import v2 as T\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import tempfile\n",
    "from functools import partial\n",
    "\n",
    "# Model Transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "# Model imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "# Data imports\n",
    "from facet_ml.classification import mask_rcnn\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Ray tune imports\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Creation Functions ###\n",
    "def get_model_instance_segmentation(num_classes,\n",
    "                                    config:dict):\n",
    "    \n",
    "    ## load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    ## Make an updated FastRCNN with backgone changes as needed\n",
    "    backbone = config.get(\"backbone\",\"resnet50\")\n",
    "    if backbone == \"mobilenet_v2\":\n",
    "        backbone = torchvision.models.mobilenet_v2(weights=\"DEFAULT\").features\n",
    "        backbone.out_channels = 1280\n",
    "        fast_rcnn = FasterRCNN(backbone, in_features=in_features, num_classes=num_classes,)\n",
    "        model.roi_heads.box_predictor = fast_rcnn\n",
    "    else:\n",
    "        # Use defualt resnet50 bacbone\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_instance_segmentation(num_classes,config):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_optimizer(model,config):\n",
    "    '''\n",
    "    Get an optimzier based on the config settings\n",
    "    '''\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if config[\"optimizer\"] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(params,\n",
    "                         lr=config[\"lr\"],\n",
    "                        weight_decay=config[\"weight_decay\"],\n",
    "                        betas=config[\"betas\"]\n",
    "            )\n",
    "    elif config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            params,\n",
    "            lr=config[\"lr\"],\n",
    "            momentum=config[\"momentum\"],\n",
    "            weight_decay=config[\"weight_decay\"] # .0005 starting\n",
    "        )\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(optimizer,config):\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=3,\n",
    "        gamma=config[\"gamma\"]\n",
    "    )\n",
    "    return lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Transforms and Data ###\n",
    "\n",
    "# Augmentation iff training!\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "        transforms.append(T.RandomRotation(90))\n",
    "        transforms.append(T.RandomResizedCrop(size=256, scale=(0.6, 1.4)))\n",
    "        T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.0)\n",
    "        # transforms.append(T.RandomCrop(size=(224, 224)))\n",
    "\n",
    "\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def load_colloidal_data(data_dir=r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\cC_Manuscript_Data\\Coco_v5\"\n",
    "):\n",
    "    train_dir = Path(data_dir) / \"train\"\n",
    "    test_dir  = Path(data_dir) / \"test\"\n",
    "    cd_train = mask_rcnn.ManualCocoColloidalDataset(\n",
    "        str(train_dir),\n",
    "        str(train_dir / \"_annotations.coco.json\"),\n",
    "        transforms=get_transform(True)\n",
    "    )\n",
    "    cd_test = mask_rcnn.ManualCocoColloidalDataset(\n",
    "        str(test_dir),\n",
    "        str(Path(test_dir) / \"_annotations.coco.json\"),\n",
    "        transforms=get_transform(False)\n",
    "    )\n",
    "\n",
    "\n",
    "    return cd_train, cd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ray Tune config parameters\n",
    "ray_config ={\n",
    "    ## Opt choice\n",
    "    \"optimizer\": tune.choice([\"Adam\",\"SGD\"]),\n",
    "\n",
    "    ## Region Choices\n",
    "    # Unused\n",
    "\n",
    "    # General choices\n",
    "    \"lr\": tune.loguniform(1e-4,1e-1),\n",
    "    \"betas\":  tune.choice([(0.9, 0.999), (0.5, 0.999)]),\n",
    "    \"momentum\": tune.uniform(0.5, 0.9),\n",
    "    \"weight_decay\": tune.loguniform(1e-4,1e-1),\n",
    "    \"gamma\": tune.uniform(0.1, 0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ray Tune Functions ##\n",
    "\n",
    "def train_colloidal(config,data_dir):\n",
    "    '''\n",
    "    Ray tune train loop\n",
    "    '''\n",
    "    device = \"cuda\"\n",
    "\n",
    "    model = get_model_instance_segmentation(2,config)\n",
    "    model.to(device)\n",
    "    optimizer = get_optimizer(model, config)\n",
    "    scheduler = get_scheduler(optimizer, config)\n",
    "\n",
    "    checkpoint = get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"rb\") as fp:\n",
    "                checkpoint_state = pickle.load(fp)\n",
    "            start_epoch = checkpoint_state[\"epoch\"]\n",
    "            model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    trainset, testset = load_colloidal_data(data_dir)\n",
    "    def collate_fn(batch):\n",
    "        '''\n",
    "        Collation function receives [(image_1, targets_1{masks,boxes,labels}), (image_10, targets_1{masks,boxes,labels})...]\n",
    "        Need to stack image_1\n",
    "        '''\n",
    "        images = [item[0] for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        # return tuple(zip(*batch))\n",
    "        return images,targets\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=2,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=2,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, targets = data\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [\n",
    "                {\n",
    "                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                    for k, v in t.items()\n",
    "                }\n",
    "                for t in targets\n",
    "            ]\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses_reduced = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses_reduced.item()\n",
    "\n",
    "            if not math.isfinite(loss_value):\n",
    "                print(f\"Loss is {loss_value}, stopping training\")\n",
    "                # print(loss_dict_reduced)\n",
    "                sys.exit(1)\n",
    "            \n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            test_loss = 0.0\n",
    "            test_steps = 0\n",
    "\n",
    "            for i, data in enumerate(test_loader,0):\n",
    "                with torch.no_grad():\n",
    "                    images, targets = data\n",
    "                    images = list(image.to(device) for image in images)\n",
    "                    targets = [\n",
    "                        {\n",
    "                            k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                            for k, v in t.items()\n",
    "                        }\n",
    "                        for t in targets\n",
    "                    ]\n",
    "                    loss_dict = model(images, targets)\n",
    "                    losses_reduced = sum(loss for loss in loss_dict.values())\n",
    "                    test_loss += losses_reduced\n",
    "                    test_steps += 1\n",
    "            \n",
    "            checkpoint_data = {\n",
    "                \"epoch\": epoch,\n",
    "                \"net_state_dict\":model.state_dict(),\n",
    "                \"optimizer_state_dict\":optimizer.state_dict()\n",
    "            }\n",
    "            with tempfile.TemporaryDirectory() as checkpoint_dir:\n",
    "                data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "                with open(data_path, \"wb\") as fp:\n",
    "                    pickle.dump(checkpoint_data, fp)\n",
    "\n",
    "                checkpoint = Checkpoint.from_directory(checkpoint_dir)\n",
    "                train.report(\n",
    "                    {\"loss\": test_loss.to(\"cpu\").detach().numpy() / test_steps, \n",
    "                    #  \"accuracy\": correct / total\n",
    "                     },\n",
    "                    checkpoint=checkpoint,\n",
    "                )\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\ProcessedData\\Coco_v5\")\n",
    "\n",
    "test_config ={\n",
    "    # Opt choice\n",
    "    \"optimizer\": \"SGD\",\n",
    "\n",
    "    # Region Choices\n",
    "\n",
    "    # General choices\n",
    "    \"lr\": 0.005,\n",
    "    \"betas\":  (0.9, 0.999),\n",
    "    \"momentum\":0.9,\n",
    "    \"weight_decay\": .5,\n",
    "    \"gamma\": 0.6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config, num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
    "    data_dir = os.path.abspath(r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\ProcessedData\\Coco_v5\")\n",
    "    load_colloidal_data(data_dir)\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    def short_dirname(trial):\n",
    "        return \"trial_\" + str(trial.trial_id)\n",
    "    \n",
    "    result = tune.run(\n",
    "        partial(train_colloidal, data_dir=data_dir),\n",
    "        # resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        trial_dirname_creator=short_dirname,\n",
    "        max_concurrent_trials=4\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "    # print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:40:46,153\tINFO worker.py:1783 -- Started a local Ray instance.\n",
      "2024-11-03 23:40:47,653\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-11-03 23:40:47,655\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-04 00:20:03</td></tr>\n",
       "<tr><td>Running for: </td><td>00:39:15.50        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.4/31.8 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=28<br>Bracket: Iter 8.000: -3.0207793712615967 | Iter 4.000: -3.2987442016601562 | Iter 2.000: -3.578793525695801 | Iter 1.000: -5.540828466415405<br>Logical resource usage: 1.0/28 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_colloidal_57ca6_00015</td><td style=\"text-align: right;\">           1</td><td>C:/Users/Jacob/AppData/Local/Temp/ray/session_2024-11-03_23-40-44_450333_54200/artifacts/2024-11-03_23-40-47/train_colloidal_2024-11-03_23-40-47/driver_artifacts/trial_57ca6_00015/error.txt</td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00023</td><td style=\"text-align: right;\">           1</td><td>C:/Users/Jacob/AppData/Local/Temp/ray/session_2024-11-03_23-40-44_450333_54200/artifacts/2024-11-03_23-40-47/train_colloidal_2024-11-03_23-40-47/driver_artifacts/trial_57ca6_00023/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>betas       </th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th>optimizer  </th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">          loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_colloidal_57ca6_00000</td><td>TERMINATED</td><td>127.0.0.1:62432</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.71103 </td><td style=\"text-align: right;\">0.0260702  </td><td style=\"text-align: right;\">  0.754554</td><td>SGD        </td><td style=\"text-align: right;\">   0.00444182 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         57.0528</td><td style=\"text-align: right;\">   9.20266    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00001</td><td>TERMINATED</td><td>127.0.0.1:62440</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.597532</td><td style=\"text-align: right;\">0.000251792</td><td style=\"text-align: right;\">  0.518651</td><td>SGD        </td><td style=\"text-align: right;\">   0.0227673  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         57.6619</td><td style=\"text-align: right;\">   9.95315    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00002</td><td>TERMINATED</td><td>127.0.0.1:62416</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.301362</td><td style=\"text-align: right;\">0.000117524</td><td style=\"text-align: right;\">  0.848071</td><td>Adam       </td><td style=\"text-align: right;\">   0.0882751  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">       2351.29  </td><td style=\"text-align: right;\">   2.68323    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00003</td><td>TERMINATED</td><td>127.0.0.1:62404</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.227879</td><td style=\"text-align: right;\">0.00030917 </td><td style=\"text-align: right;\">  0.882355</td><td>SGD        </td><td style=\"text-align: right;\">   0.000102035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         57.7297</td><td style=\"text-align: right;\">   9.46945    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00004</td><td>TERMINATED</td><td>127.0.0.1:30144</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.62551 </td><td style=\"text-align: right;\">0.000120133</td><td style=\"text-align: right;\">  0.886775</td><td>Adam       </td><td style=\"text-align: right;\">   0.00292122 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        864.212 </td><td style=\"text-align: right;\">   2.95595    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00005</td><td>TERMINATED</td><td>127.0.0.1:63400</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.124623</td><td style=\"text-align: right;\">0.000333498</td><td style=\"text-align: right;\">  0.545806</td><td>Adam       </td><td style=\"text-align: right;\">   0.0377119  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">       2280.29  </td><td style=\"text-align: right;\">   3.05577    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00006</td><td>TERMINATED</td><td>127.0.0.1:61752</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.827628</td><td style=\"text-align: right;\">0.00382336 </td><td style=\"text-align: right;\">  0.744711</td><td>SGD        </td><td style=\"text-align: right;\">   0.000937597</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        116.176 </td><td style=\"text-align: right;\">   4.17588    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00007</td><td>TERMINATED</td><td>127.0.0.1:49888</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.742266</td><td style=\"text-align: right;\">0.0250938  </td><td style=\"text-align: right;\">  0.505058</td><td>SGD        </td><td style=\"text-align: right;\">   0.0714078  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         37.8472</td><td style=\"text-align: right;\">  16.3096     </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00008</td><td>TERMINATED</td><td>127.0.0.1:41764</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.554964</td><td style=\"text-align: right;\">0.0789794  </td><td style=\"text-align: right;\">  0.745354</td><td>SGD        </td><td style=\"text-align: right;\">   0.00359084 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         37.5478</td><td style=\"text-align: right;\">8918.79       </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00009</td><td>TERMINATED</td><td>127.0.0.1:48384</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.301497</td><td style=\"text-align: right;\">0.00155265 </td><td style=\"text-align: right;\">  0.848978</td><td>Adam       </td><td style=\"text-align: right;\">   0.000700889</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.2843</td><td style=\"text-align: right;\"> 772.37       </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00010</td><td>TERMINATED</td><td>127.0.0.1:62936</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.257029</td><td style=\"text-align: right;\">0.00358841 </td><td style=\"text-align: right;\">  0.76743 </td><td>SGD        </td><td style=\"text-align: right;\">   0.000369579</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         89.6006</td><td style=\"text-align: right;\">   4.48411    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00011</td><td>TERMINATED</td><td>127.0.0.1:62932</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.693409</td><td style=\"text-align: right;\">0.0104342  </td><td style=\"text-align: right;\">  0.600189</td><td>SGD        </td><td style=\"text-align: right;\">   0.000331606</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         95.1869</td><td style=\"text-align: right;\">   4.65172    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00012</td><td>TERMINATED</td><td>127.0.0.1:24596</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.86109 </td><td style=\"text-align: right;\">0.00109892 </td><td style=\"text-align: right;\">  0.840112</td><td>Adam       </td><td style=\"text-align: right;\">   0.00387342 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.9325</td><td style=\"text-align: right;\">  15.8823     </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00013</td><td>TERMINATED</td><td>127.0.0.1:52844</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.576757</td><td style=\"text-align: right;\">0.000224653</td><td style=\"text-align: right;\">  0.877593</td><td>Adam       </td><td style=\"text-align: right;\">   0.00038396 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        580.837 </td><td style=\"text-align: right;\">   2.49862    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00014</td><td>TERMINATED</td><td>127.0.0.1:27524</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.21629 </td><td style=\"text-align: right;\">0.000757941</td><td style=\"text-align: right;\">  0.875393</td><td>Adam       </td><td style=\"text-align: right;\">   0.0592825  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         95.5782</td><td style=\"text-align: right;\">   7.53945    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00016</td><td>TERMINATED</td><td>127.0.0.1:10028</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.646779</td><td style=\"text-align: right;\">0.0026658  </td><td style=\"text-align: right;\">  0.786441</td><td>Adam       </td><td style=\"text-align: right;\">   0.00182031 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.8289</td><td style=\"text-align: right;\">   9.24369e+08</td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00017</td><td>TERMINATED</td><td>127.0.0.1:24004</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.475269</td><td style=\"text-align: right;\">0.0147788  </td><td style=\"text-align: right;\">  0.824539</td><td>SGD        </td><td style=\"text-align: right;\">   0.00767801 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        768.476 </td><td style=\"text-align: right;\"> 158.603      </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00018</td><td>TERMINATED</td><td>127.0.0.1:56860</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.774962</td><td style=\"text-align: right;\">0.00112524 </td><td style=\"text-align: right;\">  0.881472</td><td>SGD        </td><td style=\"text-align: right;\">   0.00197835 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        160.014 </td><td style=\"text-align: right;\">   4.21589    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00019</td><td>TERMINATED</td><td>127.0.0.1:56756</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.795987</td><td style=\"text-align: right;\">0.000114623</td><td style=\"text-align: right;\">  0.836806</td><td>SGD        </td><td style=\"text-align: right;\">   0.0642007  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         42.2675</td><td style=\"text-align: right;\">   8.89267    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00020</td><td>TERMINATED</td><td>127.0.0.1:42312</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.897156</td><td style=\"text-align: right;\">0.00132818 </td><td style=\"text-align: right;\">  0.798843</td><td>Adam       </td><td style=\"text-align: right;\">   0.000402036</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.9408</td><td style=\"text-align: right;\">  68.2836     </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00021</td><td>TERMINATED</td><td>127.0.0.1:56212</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.128416</td><td style=\"text-align: right;\">0.000114936</td><td style=\"text-align: right;\">  0.577945</td><td>Adam       </td><td style=\"text-align: right;\">   0.000458774</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        478.091 </td><td style=\"text-align: right;\">   3.14706    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00022</td><td>TERMINATED</td><td>127.0.0.1:51760</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.80236 </td><td style=\"text-align: right;\">0.0204622  </td><td style=\"text-align: right;\">  0.753745</td><td>SGD        </td><td style=\"text-align: right;\">   0.0155731  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.8188</td><td style=\"text-align: right;\">   9.07487    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00024</td><td>TERMINATED</td><td>127.0.0.1:30136</td><td>(0.9, 0.999)</td><td style=\"text-align: right;\">0.762585</td><td style=\"text-align: right;\">0.000378251</td><td style=\"text-align: right;\">  0.743896</td><td>Adam       </td><td style=\"text-align: right;\">   0.00665586 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         59.3805</td><td style=\"text-align: right;\">   3.57879    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00025</td><td>TERMINATED</td><td>127.0.0.1:62472</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.722641</td><td style=\"text-align: right;\">0.000664229</td><td style=\"text-align: right;\">  0.888262</td><td>Adam       </td><td style=\"text-align: right;\">   0.000983842</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.5143</td><td style=\"text-align: right;\">   7.84075    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00026</td><td>TERMINATED</td><td>127.0.0.1:46508</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.542491</td><td style=\"text-align: right;\">0.00590431 </td><td style=\"text-align: right;\">  0.89691 </td><td>SGD        </td><td style=\"text-align: right;\">   0.0109084  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        295.062 </td><td style=\"text-align: right;\">   4.66446    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00027</td><td>TERMINATED</td><td>127.0.0.1:2752 </td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.376249</td><td style=\"text-align: right;\">0.00355355 </td><td style=\"text-align: right;\">  0.832825</td><td>Adam       </td><td style=\"text-align: right;\">   0.0131637  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         51.006 </td><td style=\"text-align: right;\">   7.90782e+12</td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00028</td><td>TERMINATED</td><td>127.0.0.1:62992</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.213369</td><td style=\"text-align: right;\">0.00251473 </td><td style=\"text-align: right;\">  0.876423</td><td>SGD        </td><td style=\"text-align: right;\">   0.0470317  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         87.3369</td><td style=\"text-align: right;\">   3.5117     </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00029</td><td>TERMINATED</td><td>127.0.0.1:55300</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.381145</td><td style=\"text-align: right;\">0.0077354  </td><td style=\"text-align: right;\">  0.8596  </td><td>SGD        </td><td style=\"text-align: right;\">   0.000869016</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         98.1538</td><td style=\"text-align: right;\">   4.06629    </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00015</td><td>ERROR     </td><td>127.0.0.1:55624</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.565066</td><td style=\"text-align: right;\">0.0518487  </td><td style=\"text-align: right;\">  0.784905</td><td>Adam       </td><td style=\"text-align: right;\">   0.00258212 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.195 </td><td style=\"text-align: right;\"> nan          </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00023</td><td>ERROR     </td><td>127.0.0.1:63020</td><td>(0.5, 0.999)</td><td style=\"text-align: right;\">0.684047</td><td style=\"text-align: right;\">0.0148533  </td><td style=\"text-align: right;\">  0.613394</td><td>Adam       </td><td style=\"text-align: right;\">   0.00289466 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.3315</td><td style=\"text-align: right;\"> nan          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=62416)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=62416)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000000)\n",
      "\u001b[36m(func pid=62440)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(func pid=62440)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">          loss</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_colloidal_57ca6_00000</td><td style=\"text-align: right;\">   9.20266    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00001</td><td style=\"text-align: right;\">   9.95315    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00002</td><td style=\"text-align: right;\">   2.68323    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00003</td><td style=\"text-align: right;\">   9.46945    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00004</td><td style=\"text-align: right;\">   2.95595    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00005</td><td style=\"text-align: right;\">   3.05577    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00006</td><td style=\"text-align: right;\">   4.17588    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00007</td><td style=\"text-align: right;\">  16.3096     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00008</td><td style=\"text-align: right;\">8918.79       </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00009</td><td style=\"text-align: right;\"> 772.37       </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00010</td><td style=\"text-align: right;\">   4.48411    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00011</td><td style=\"text-align: right;\">   4.65172    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00012</td><td style=\"text-align: right;\">  15.8823     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00013</td><td style=\"text-align: right;\">   2.49862    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00014</td><td style=\"text-align: right;\">   7.53945    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00015</td><td style=\"text-align: right;\"> nan          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00016</td><td style=\"text-align: right;\">   9.24369e+08</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00017</td><td style=\"text-align: right;\"> 158.603      </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00018</td><td style=\"text-align: right;\">   4.21589    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00019</td><td style=\"text-align: right;\">   8.89267    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00020</td><td style=\"text-align: right;\">  68.2836     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00021</td><td style=\"text-align: right;\">   3.14706    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00022</td><td style=\"text-align: right;\">   9.07487    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00023</td><td style=\"text-align: right;\"> nan          </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00024</td><td style=\"text-align: right;\">   3.57879    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00025</td><td style=\"text-align: right;\">   7.84075    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00026</td><td style=\"text-align: right;\">   4.66446    </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00027</td><td style=\"text-align: right;\">   7.90782e+12</td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00028</td><td style=\"text-align: right;\">   3.5117     </td><td>True               </td></tr>\n",
       "<tr><td>train_colloidal_57ca6_00029</td><td style=\"text-align: right;\">   4.06629    </td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:41:49,060\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "2024-11-03 23:41:49,627\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "2024-11-03 23:41:49,652\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=62440)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00001/checkpoint_000000)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(func pid=61752)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=61752)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=30144)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=30144)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000000)\n",
      "\u001b[36m(func pid=63400)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=63400)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=61752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00006/checkpoint_000000)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000001)\n",
      "2024-11-03 23:43:52,127\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=61752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00006/checkpoint_000001)\n",
      "\u001b[36m(func pid=49888)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=49888)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000002)\n",
      "2024-11-03 23:44:35,205\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=49888)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00007/checkpoint_000000)\n",
      "\u001b[36m(func pid=41764)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=41764)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-03 23:45:16,260\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=41764)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00008/checkpoint_000000)\n",
      "\u001b[36m(func pid=48384)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=48384)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000003)\n",
      "2024-11-03 23:45:57,925\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=48384)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00009/checkpoint_000000)\n",
      "\u001b[36m(func pid=62936)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=62936)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62936)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00010/checkpoint_000000)\n",
      "2024-11-03 23:47:31,019\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=62936)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00010/checkpoint_000001)\n",
      "\u001b[36m(func pid=62932)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=62932)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62932)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00011/checkpoint_000000)\n",
      "2024-11-03 23:49:09,610\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=62932)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00011/checkpoint_000001)\n",
      "\u001b[36m(func pid=24596)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=24596)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=24596)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00012/checkpoint_000000)\n",
      "2024-11-03 23:49:52,004\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=52844)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=52844)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000004)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000000)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000005)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000001)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000002)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000006)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000003)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000007)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000004)\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000008)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000005)\n",
      "2024-11-03 23:56:20,289\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=30144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00004/checkpoint_000009)\n",
      "\u001b[36m(func pid=27524)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=27524)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000006)\n",
      "\u001b[36m(func pid=27524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00014/checkpoint_000000)\n",
      "2024-11-03 23:57:59,461\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=27524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00014/checkpoint_000001)\n",
      "\u001b[36m(func pid=55624)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=55624)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000007)\n",
      "\u001b[36m(func pid=55624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00015/checkpoint_000000)\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000008)\n",
      "2024-11-03 23:59:09,459\tERROR tune_controller.py:1331 -- Trial task failed for trial train_colloidal_57ca6_00015\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 873, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ImplicitFunc\n",
      "\tactor_id: 188098f0d8b316521c880fc801000000\n",
      "\tpid: 55624\n",
      "\tnamespace: e40db703-9a31-4977-95e0-bc2efd7a3053\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff188098f0d8b316521c880fc801000000 Worker ID: 7ff48a6779fad41a5559179386ab41a16a945b4ee7e642e7664ff6ca Node ID: 9c53e45550f8f7a91dbda7951901aa8724c65ce0d30ee3238c0304c1 Worker IP address: 127.0.0.1 Worker port: 50869 Worker PID: 55624 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:59:09,474\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=55624)\u001b[0m Loss is nan, stopping training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=10028)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=10028)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000001)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000000)\n",
      "2024-11-03 23:59:36,318\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=52844)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00013/checkpoint_000009)\n",
      "\u001b[36m(func pid=24004)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=24004)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-03 23:59:49,039\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=10028)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00016/checkpoint_000000)\n",
      "\u001b[36m(func pid=56860)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=56860)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000002)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000001)\n",
      "\u001b[36m(func pid=56860)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00018/checkpoint_000000)\n",
      "\u001b[36m(func pid=56860)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00018/checkpoint_000001)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000002)\n",
      "\u001b[36m(func pid=56860)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00018/checkpoint_000002)\n",
      "2024-11-04 00:02:32,901\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=56860)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00018/checkpoint_000003)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000003)\n",
      "\u001b[36m(func pid=56756)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=56756)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-04 00:03:19,567\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=56756)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00019/checkpoint_000000)\n",
      "\u001b[36m(func pid=42312)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=42312)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=24004)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00017/checkpoint_000000)\n",
      "2024-11-04 00:04:05,251\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=42312)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00020/checkpoint_000000)\n",
      "\u001b[36m(func pid=56212)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=56212)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000000)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000001)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000002)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000003)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000004)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000005)\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000006)\n",
      "2024-11-04 00:12:07,359\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=56212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00021/checkpoint_000007)\n",
      "\u001b[36m(func pid=51760)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=51760)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-04 00:12:28,607\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=24004)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00017/checkpoint_000001)\n",
      "\u001b[36m(func pid=63020)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=63020)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-04 00:12:42,144\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=51760)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00022/checkpoint_000000)\n",
      "\u001b[36m(func pid=30136)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=30136)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000004)\n",
      "\u001b[36m(func pid=30136)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00024/checkpoint_000000)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2024-11-04 00:13:26,434\tERROR tune_controller.py:1331 -- Trial task failed for trial train_colloidal_57ca6_00023\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\_private\\worker.py\", line 873, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ImplicitFunc\n",
      "\tactor_id: 7dd2eea48b21b803947359fb01000000\n",
      "\tpid: 63020\n",
      "\tnamespace: e40db703-9a31-4977-95e0-bc2efd7a3053\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=63020)\u001b[0m Loss is nan, stopping training\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff7dd2eea48b21b803947359fb01000000 Worker ID: fa8ecdb741611bfb9b5fa17addcec6fc228a56a60da65353dada7cb4 Node ID: 9c53e45550f8f7a91dbda7951901aa8724c65ce0d30ee3238c0304c1 Worker IP address: 127.0.0.1 Worker port: 51829 Worker PID: 63020 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 00:13:26,440\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000004)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000005)\n",
      "\u001b[36m(func pid=62472)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=62472)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-04 00:13:45,169\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=30136)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00024/checkpoint_000001)\n",
      "\u001b[36m(func pid=46508)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=46508)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "2024-11-04 00:13:57,680\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=62472)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00025/checkpoint_000000)\n",
      "\u001b[36m(func pid=2752)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=2752)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000005)\n",
      "2024-11-04 00:14:52,270\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=2752)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00027/checkpoint_000000)\n",
      "\u001b[36m(func pid=62992)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=62992)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=62992)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00028/checkpoint_000000)\n",
      "2024-11-04 00:16:23,165\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=62992)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00028/checkpoint_000001)\n",
      "\u001b[36m(func pid=55300)\u001b[0m c:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\torchvision\\tv_tensors\\_tv_tensor.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "\u001b[36m(func pid=55300)\u001b[0m   return torch.as_tensor(data, dtype=dtype, device=device).requires_grad_(requires_grad)\n",
      "\u001b[36m(func pid=55300)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00029/checkpoint_000000)\n",
      "2024-11-04 00:18:04,887\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=55300)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00029/checkpoint_000001)\n",
      "\u001b[36m(func pid=46508)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00026/checkpoint_000000)\n",
      "2024-11-04 00:18:44,212\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=46508)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00026/checkpoint_000001)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000006)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000006)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000007)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000007)\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000008)\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000008)\n",
      "2024-11-04 00:19:56,293\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.5, 0.999)}\n",
      "\u001b[36m(func pid=63400)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00005/checkpoint_000009)\n",
      "2024-11-04 00:20:03,173\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'betas': (0.9, 0.999)}\n",
      "\u001b[36m(func pid=62416)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47/trial_57ca6_00002/checkpoint_000009)\n",
      "2024-11-04 00:20:03,207\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Jacob/ray_results/train_colloidal_2024-11-03_23-40-47' in 0.0295s.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_colloidal_57ca6_00015, train_colloidal_57ca6_00023])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mray_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config, num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshort_dirname\u001b[39m(trial):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_colloidal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_dirname_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshort_dirname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_concurrent_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_best_trial(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_trial\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\colloidal_crystal_env\\lib\\site-packages\\ray\\tune\\tune.py:1035\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_colloidal_57ca6_00015, train_colloidal_57ca6_00023])"
     ]
    }
   ],
   "source": [
    "main(ray_config,num_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config:  {'optimizer': 'Adam', 'lr': 0.00016517420107310982, 'betas': [0.5, 0.999], 'momentum': 0.5277638298935976, 'weight_decay': 0.0006188018644099798, 'gamma': 0.512368076225412}\n",
      "Best trial final result:  {'loss': 2.4554710388183594, 'timestamp': 1726167629, 'checkpoint_dir_name': 'checkpoint_000009', 'should_checkpoint': True, 'done': True, 'training_iteration': 10, 'trial_id': '03f42_00012', 'date': '2024-09-12_14-00-29', 'time_this_iter_s': 38.13473606109619, 'time_total_s': 319.3866858482361, 'pid': 22496, 'hostname': 'DESKTOP-RD74FOL', 'node_ip': '127.0.0.1', 'config': {'optimizer': 'Adam', 'lr': 0.00016517420107310982, 'betas': [0.5, 0.999], 'momentum': 0.5277638298935976, 'weight_decay': 0.0006188018644099798, 'gamma': 0.512368076225412}, 'time_since_restore': 319.3866858482361, 'iterations_since_restore': 10, 'experiment_tag': '12_betas=0_5_0_999,gamma=0.5124,lr=0.0002,momentum=0.5278,optimizer=Adam,weight_decay=0.0006'}\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "folder_path = r\"C:/Users/Jacob/ray_results/train_colloidal_2024-09-12_12-11-14\" \n",
    "analysis = ExperimentAnalysis(folder_path)\n",
    "\n",
    "completed_trials = [trial for trial in analysis.trials if trial.status == \"TERMINATED\"]\n",
    "failed_trials = [trial for trial in analysis.trials if trial.status == \"ERROR\"]\n",
    "\n",
    "best_trial = min(completed_trials, key=lambda trial: trial.last_result[\"loss\"])\n",
    "\n",
    "# Print the best performing trial and its results\n",
    "print(\"Best trial config: \", best_trial.config)\n",
    "print(\"Best trial final result: \", best_trial.last_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colloidal_crystal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
