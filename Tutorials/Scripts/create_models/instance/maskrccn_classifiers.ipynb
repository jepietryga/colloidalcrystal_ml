{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A lot of code is taken from <a href=\"https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\"> PyTorch tutorial on Finetuning </a>\n",
    "\n",
    "Parameters are coming from raytune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.transforms import v2 as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from facet_ml.classification import mask_rcnn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "        transforms.append(T.RandomRotation(90))\n",
    "        # transforms.append(T.RandomResizedCrop(size=256, scale=(0.6, 1.4)))\n",
    "        transforms.append(T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1))\n",
    "        # transforms.append(T.RandomCrop(size=(224, 224)))\n",
    "\n",
    "\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data ##\n",
    "\n",
    "device = \"cuda\"\n",
    "# Coco folder\n",
    "coco_dir = r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\ProcessedData\\Coco_v5\"\n",
    "coco_dir_train = str( Path(coco_dir) / \"train\" )\n",
    "coco_dir_test = str( Path(coco_dir) / \"test\" )\n",
    "\n",
    "cd_train = mask_rcnn.ManualCocoColloidalDataset(coco_dir_train, \n",
    "                                             str(Path(coco_dir_train) / \"_annotations.coco.json\"),\n",
    "                                             transforms=get_transform(True)\n",
    "                                             )\n",
    "cd_test = mask_rcnn.ManualCocoColloidalDataset(coco_dir_test, \n",
    "                                            str(Path(coco_dir_test) / \"_annotations.coco.json\"),\n",
    "                                            transforms=get_transform(False)\n",
    "                                            )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "    Collation function receives [(image_1, targets_1{masks,boxes,labels}), (image_10, targets_1{masks,boxes,labels})...]\n",
    "    Need to stack image_1\n",
    "    '''\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    # return tuple(zip(*batch))\n",
    "    return images,targets\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    cd_train,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    cd_test,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model using our helper function\n",
    "num_classes=2\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.5 # .0005 starting\n",
    ")\n",
    "optimizer = torch.optim.Adam(\n",
    "    params,\n",
    "    lr=0.000165,\n",
    "    betas=[0.5, 0.999],\n",
    "    weight_decay=0.000618,\n",
    "\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.6\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma = .512368\n",
    ")\n",
    "\n",
    "# For testing, train it just for 10 epochs. Otherwise, 100\n",
    "num_epochs = 10\n",
    "\n",
    "metric_loggers = []\n",
    "total_losses = []\n",
    "from engine import train_one_epoch,evaluate\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, targets in dataloader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Forward pass (get the model's predictions)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss (same loss used in training, if applicable)\n",
    "            loss_dict = model(images, targets)\n",
    "            print(loss_dict)\n",
    "            print(loss_dict[0].keys())\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "            \n",
    "            all_predictions.append(outputs)\n",
    "\n",
    "    avg_val_loss = val_loss / len(dataloader)\n",
    "    return avg_val_loss, all_predictions\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train epochs\n",
    "    metric_logger = train_one_epoch(model, optimizer, dataloader_train, device,epoch,print_freq=1)\n",
    "    # metric_loggers.append( train_one_epoch(model, optimizer, dataloader_train, device,epoch,print_freq=1) )\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target image\n",
    "image_oi, targets_oi = cd_test[0]\n",
    "\n",
    "targets_oi = [\n",
    "    {\n",
    "        k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "        for k, v in targets_oi.items()\n",
    "    }\n",
    "]\n",
    "model.train()\n",
    "out = model([ image_oi.to(\"cuda\") ],targets_oi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model([ image_oi.to(\"cuda\") ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets_oi[0]\n",
    "targets = out[0]\n",
    "print(targets)\n",
    "\n",
    "masks = targets[\"masks\"]\n",
    "print(\"masks:\", masks.shape)\n",
    "boxes = targets[\"boxes\"]\n",
    "labels = targets[\"labels\"]\n",
    "scores = targets.get(\"scores\",None)\n",
    "\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path as plt_Path \n",
    "def draw_polygon_with_paths(box,ax):\n",
    "    # rect = patches.Rectangle( (box[3],box[1]), box[2], box[0],face_color=None)\n",
    "    vertices = [\n",
    "        (box[0],box[1]), # Topleft\n",
    "        (box[0],box[3]), # Bottom Left\n",
    "        (box[2],box[3]), # Bottom Right\n",
    "        (box[2],box[1]), # Top Right\n",
    "        (box[0],box[1])  # Top Left\n",
    "    ]\n",
    "    codes = [\n",
    "        plt_Path.MOVETO,  # Move to the first point (start)\n",
    "        plt_Path.LINETO,  # Line to the second point\n",
    "        plt_Path.LINETO,  # Line to the third point\n",
    "        plt_Path.LINETO,  # Line to the fourth point\n",
    "        plt_Path.CLOSEPOLY  # Close the path (back to the start)\n",
    "    ]\n",
    "    path = plt_Path(vertices, codes)\n",
    "    patch = patches.PathPatch(path, facecolor='none', edgecolor='blue', linewidth=2,alpha=.1)\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "def draw_mask_with_mask(mask,ax):\n",
    "    from matplotlib.colors import ListedColormap, Normalize\n",
    "    cmap = ListedColormap(['none', 'red'])\n",
    "    ax.imshow(mask,cmap=cmap,alpha=.5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image_oi[0,:,:])\n",
    "\n",
    "from IPython.display import clear_output\n",
    "for ii in range(len(masks)):\n",
    "    if scores is not None:\n",
    "        \n",
    "        if scores[ii] < .5:\n",
    "            continue\n",
    "    if len(masks[ii].shape) == 3:\n",
    "        mask = masks[ii][0].to(\"cpu\").detach()\n",
    "    else:\n",
    "        mask = masks[ii].to(\"cpu\").detach()\n",
    "    # mask = masks[ii][0].to(\"cpu\").detach()\n",
    "    box = boxes[ii].to(\"cpu\").detach()\n",
    "    label = labels[ii]\n",
    "    \n",
    "    draw_polygon_with_paths(box,ax)\n",
    "    draw_mask_with_mask(mask,ax)\n",
    "    # print(box)\n",
    "    # plt.show()\n",
    "    # from time import sleep\n",
    "    # sleep(.1)\n",
    "    # clear_output(wait=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_item = next(iter(dataloader_train))\n",
    "img_load, targets_load = (next_item[0][0],next_item[1][0])\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_load[0,:,:])\n",
    "\n",
    "masks_load = targets_load[\"masks\"]\n",
    "\n",
    "for ii in range(masks_load.shape[0]):\n",
    "    mask = masks_load[ii]\n",
    "    draw_mask_with_mask(mask,ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check model with completely new image\n",
    "image_dir = r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\Images\\Additional\\L1_2.5_5_10_nM\\L1 2.5 nM\"\n",
    "image_path = r\"C:\\Users\\Jacob\\Desktop\\Academics\\Mirkin\\colloidal_crystal_ML\\Images\\Additional\\L1_2.5_5_10_nM\\L1 2.5 nM\\L1_2.5nM_003.jpg\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "img_list = glob.glob( str(Path(image_dir) / \"*\") )\n",
    "im = cv2.imread(image_path)\n",
    "im = cv2.imread(img_list[1])\n",
    "im_torch = torch.tensor(np.moveaxis(im,-1,0)).to(\"cuda\") / 255\n",
    "out = model([im_torch])\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(im[:,:,0])\n",
    "\n",
    "masks = out[0][\"masks\"]\n",
    "boxes = out[0][\"boxes\"]\n",
    "scores = out[0][\"scores\"]\n",
    "\n",
    "for ii,mask in enumerate(masks):\n",
    "    score = scores[ii]\n",
    "    if score < .5:\n",
    "        continue\n",
    "    draw_mask_with_mask(mask.to(\"cpu\").detach()[0],ax)\n",
    "    box = boxes[ii].to(\"cpu\").detach()\n",
    "    draw_polygon_with_paths(box,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cd_train.coco[\"annotations\"]) + len(cd_test.coco[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"maskrcnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colloidal_crystal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
